# ğŸš€ QUICK START GUIDE

## 0. Setup Virtual Environment (Khuyáº¿n nghá»‹)

```bash
# Táº¡o venv
python -m venv venv

# KÃ­ch hoáº¡t
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# CÃ i dependencies
pip install -r requirements.txt
```

**Sau nÃ y**: LuÃ´n activate venv trÆ°á»›c khi cháº¡y báº¥t ká»³ lá»‡nh nÃ o.

---

## 1. Cháº¡y vá»›i Mock Model (Test ngay)

```bash
# Start server
python main.py

# Server sáº½ cháº¡y táº¡i http://localhost:8000
```

Hoáº·c test trá»±c tiáº¿p:

```bash
python test_core.py
```

---

## 2. Chá»n Model Provider (OpenAI/Anthropic/Local)

### BÆ°á»›c 1: Copy file config máº«u

```bash
cp .env.example .env
```

### BÆ°á»›c 2: Edit `.env` Ä‘á»ƒ chá»n provider

**OPTION 1: OpenAI (GPT-4)**
```bash
MODEL_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4  # hoáº·c gpt-3.5-turbo
```

**OPTION 2: Anthropic (Claude)**
```bash
MODEL_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
```

**OPTION 3: Local Model (LM Studio/Ollama/vLLM)**
```bash
MODEL_PROVIDER=local
LOCAL_MODEL_URL=http://localhost:1234  # LM Studio
LOCAL_MODEL_NAME=mistral-7b

# Ollama: LOCAL_MODEL_URL=http://localhost:11434
# vLLM: LOCAL_MODEL_URL=http://localhost:8080
```

**LÆ°u Ã½**: Local models dÃ¹ng OpenAI-compatible API (`/v1/chat/completions`)

**OPTION 4: Mock (default - no API needed)**
```bash
MODEL_PROVIDER=mock
```

### BÆ°á»›c 3: Restart server

```bash
python main.py
# Log sáº½ hiá»‡n: "AI Core initialized with provider: openai"
```

---

## 3. Test API vá»›i curl

```bash
# Chat
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Xin chÃ o!"}'

# New session
curl -X POST http://localhost:8000/chat/new-session

# Get history
curl http://localhost:8000/chat/history/{session_id}

# Stats
curl http://localhost:8000/admin/stats
```

---

## 4. Test API vá»›i Python

```python
import requests

# Chat
response = requests.post(
    "http://localhost:8000/chat",
    json={"message": "Xin chÃ o!"}
)

result = response.json()
print(result["response"])
print(f"Session: {result['session_id']}")
print(f"Persona: {result['metadata']['persona']}")

# Continue conversation
response = requests.post(
    "http://localhost:8000/chat",
    json={
        "message": "Code Python cho tÃ´i",
        "session_id": result["session_id"]
    }
)

print(response.json()["response"])
```

---4

## 5. Sá»­ dá»¥ng trong code

```python
import asyncio
from app.core import AICore
from app.model import ModelClient

async def main():
    # Mock model
    model = ModelClient(provider="mock")
    
    # Hoáº·c OpenAI
    # model = ModelClient(
    #     provider="openai",
    #     api_key="sk-...",
    #     model_name="gpt-4"
    # )
    
    ai = AICore(model_client=model)
    
    # Chat
    result = await ai.process("Xin chÃ o!")
    print(result["response"])
    
    # Continue vá»›i session
    session_id = result["session_id"]
    result = await ai.process(
        "Giáº£i thÃ­ch cho tÃ´i vá» AI",
        session_id=session_id
    )
    print(result["response"])

asyncio.run(main())
```

---

## 5. TÃ¹y chá»‰nh Personas

Edit `app/config/persona.yaml`:

```yaml
personas:
  my_custom:
    name: "My Custom"
    description: "MÃ´ táº£ cá»§a báº¡n"
    temperature: 0.7
    tone:
      - "vui váº»"
      - "sÃ¡ng táº¡o"
    patterns:
      - "dÃ¹ng vÃ­ dá»¥"
      - "giáº£i thÃ­ch Ä‘Æ¡n giáº£n"
```

Sau Ä‘Ã³ persona selector sáº½ tá»± Ä‘á»™ng detect vÃ  dÃ¹ng.

---

## 6. TÃ¹y chá»‰nh Context Detection

Edit `app/config/rules.yaml`:

```yaml
context_detection:
  my_context:
    keywords:
      - "tá»« khÃ³a 1"
      - "tá»« khÃ³a 2"
    confidence_threshold: 0.6
```

---

## 7. ThÃªm Tool má»›i

```python
# app/tools/my_tool.py
from app.tools.base import BaseTool, ToolInput, ToolOutput

class MyTool(BaseTool):
    def __init__(self):
        super().__init__(
            name="my_tool",
            description="MÃ´ táº£ tool cá»§a báº¡n"
        )
    
    async def execute(self, input_data: ToolInput) -> ToolOutput:
        # Logic cá»§a báº¡n
        return ToolOutput(
            success=True,
            data={"result": "something"},
            error=None
        )

# ÄÄƒng kÃ½ trong app/api/chat.py
from app.tools.my_tool import MyTool

tool_router = ToolRouter()
tool_router.register(MyTool())
```

---

## ğŸ“š Xem thÃªm

- [README.md](README.md) - Documentation Ä‘áº§y Ä‘á»§
- [BUILD_SUMMARY.md](BUILD_SUMMARY.md) - Tá»•ng káº¿t build
- [CHANGELOG.md](CHANGELOG.md) - Version history
- [TODO.md](TODO.md) - Progress tracking

---

**Happy coding! ğŸ‰**
