# AI CORE

**Flexible Conversational AI Framework** vá»›i tÃ­nh cÃ¡ch vÃ  nháº­n thá»©c ngá»¯ cáº£nh.

> ğŸ¯ **Hybrid Approach**: Framework linh hoáº¡t - dÃ¹ng external LLMs (OpenAI/Anthropic) hoáº·c local models (LM Studio/Ollama).

## ğŸ¯ Äáº·c Ä‘iá»ƒm

- **Tá»± nhiÃªn**: NÃ³i chuyá»‡n nhÆ° ngÆ°á»i tháº­t, cÃ³ duyÃªn, biáº¿t Ä‘Ã¹a
- **Trung thá»±c**: KhÃ´ng bá»‹a kiáº¿n thá»©c, thá»«a nháº­n khi khÃ´ng biáº¿t
- **ThÃ´ng minh**: Tá»± nháº­n biáº¿t ngá»¯ cáº£nh Ä‘á»ƒ Ä‘iá»u chá»‰nh giá»ng Ä‘iá»‡u
- **Má»Ÿ rá»™ng**: Dá»… dÃ ng thÃªm tools, models, vÃ  knowledge
- **á»”n Ä‘á»‹nh**: OpenAI API compliant vá»›i robust error handling

## ğŸ—ï¸ Kiáº¿n trÃºc

```
User Input
   â†“
Context Analyzer (phÃ¢n tÃ­ch ngá»¯ cáº£nh)
   â†“
Persona Selector (chá»n tÃ­nh cÃ¡ch)
   â†“
Memory Loader (load lá»‹ch sá»­)
   â†“
Prompt Builder (xÃ¢y prompt)
   â†“
Model Client (gá»i LLM)
   â†“
Output Processor (xá»­ lÃ½ output)
   â†“
Response
```

## ğŸ“¦ Quick Setup

```bash
# Clone & setup
git clone <repo-url>
cd ai-core

# Install (see QUICK_START.md for details)
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

# Run
python main.py  # â†’ http://localhost:8000
```

ğŸ“˜ **[â†’ Äá»c QUICK_START.md](QUICK_START.md)** Ä‘á»ƒ biáº¿t chi tiáº¿t setup vá»›i OpenAI/Anthropic/Local models

## ğŸ“¡ API Endpoints

### POST /chat
Gá»­i tin nháº¯n vÃ  nháº­n pháº£n há»“i

```json
{
  "message": "Xin chÃ o!",
  "session_id": "optional-session-id"
}
```

### POST /chat/new-session
Táº¡o session má»›i

### GET /chat/history/{session_id}
Láº¥y lá»‹ch sá»­ chat

### DELETE /chat/session/{session_id}
XÃ³a session

## ğŸ¨ Personas

- **Casual**: Thoáº£i mÃ¡i, vui váº», Ä‘Ã¹a giá»¡n
- **Technical**: NghiÃªm tÃºc, chÃ­nh xÃ¡c, chi tiáº¿t
- **Cautious**: Cáº©n tháº­n, thá»«a nháº­n khi khÃ´ng biáº¿t

AI tá»± Ä‘á»™ng chá»n persona dá»±a trÃªn ngá»¯ cáº£nh.

## ğŸ› ï¸ Configuration

### Model Providers
Máº·c Ä‘á»‹nh: **Mock** (testing, no API key)  
Production: **OpenAI** | **Anthropic** | **Local**

```bash
# Setup trong 3 bÆ°á»›c:
cp .env.example .env
# Edit .env â†’ chá»n provider
python main.py
```

ğŸ“˜ **[â†’ Xem QUICK_START.md](QUICK_START.md)** Ä‘á»ƒ config chi tiáº¿t vá»›i tá»«ng provider

### Personas & Rules
Edit config files trong `app/config/`:
- `persona.yaml` - 3 personas (Casual/Technical/Cautious)
- `rules.yaml` - Context detection rules
- `system.yaml` - System settings

## ğŸ“š ThÆ° má»¥c

```
ai-core/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/          # FastAPI endpoints
â”‚   â”œâ”€â”€ core/         # AI Core logic
â”‚   â”œâ”€â”€ memory/       # Memory management
â”‚   â”œâ”€â”€ model/        # Model clients
â”‚   â”œâ”€â”€ tools/        # Tool system
â”‚   â””â”€â”€ config/       # Configuration files
â”œâ”€â”€ data/             # Data storage
â”œâ”€â”€ tests/            # Tests
â””â”€â”€ main.py           # Entry point
```

## ğŸ§ª Testing

```bash
# Quick test vá»›i mock model
python test_core.py  # â†’ 4/4 tests pass

# Test API
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Xin chÃ o!"}'
```

ğŸ“˜ **[â†’ Xem QUICK_START.md](QUICK_START.md)** cho examples vá»›i Python, custom tools, personas

---

## ğŸ“š Documentation

| File | Purpose |
|------|---------|
| **[QUICK_START.md](QUICK_START.md)** | Step-by-step setup guide |
| **[CODEBASE_ANALYSIS.md](CODEBASE_ANALYSIS.md)** | Technical deep dive |
| **[STRUCTURE.md](STRUCTURE.md)** | Project structure |
| **[CHANGELOG.md](CHANGELOG.md)** | Version history |
| **[TODO.md](TODO.md)** | Progress tracking |

---

## ğŸ“ License

MIT

## ğŸ¤ Contributing

Pull requests welcome!